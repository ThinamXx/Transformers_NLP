## **Model Architecture of Transformer**

The [**Positional Encoding**](https://github.com/ThinamXx/Transformers_NLP/blob/main/01.%20Transformers%20for%20NLP/01.%20Transformer%20Architecture/PositionalEncoding_M.ipynb) notebook contains information about Positional Encoding, Word Embeddings and Positional Vectors. 

The [**Transformer Architecture**](https://github.com/ThinamXx/Transformers_NLP/blob/main/01.%20Transformers%20for%20NLP/01.%20Transformer%20Architecture/TransformerArchitecture_T.ipynb) notebook contains information about Input Embedding, Multi-head Attention, Weight Matrices, Matrix Multiplication and Attention Representations. 

**Note:**
  - üìù[**Positional Encoding**](https://github.com/ThinamXx/Transformers_NLP/blob/main/01.%20Transformers%20for%20NLP/01.%20Transformer%20Architecture/PositionalEncoding_M.ipynb)
  - üìù[**Transformer Architecture**](https://github.com/ThinamXx/Transformers_NLP/blob/main/01.%20Transformers%20for%20NLP/01.%20Transformer%20Architecture/TransformerArchitecture_T.ipynb)

