## **Tokenizers and Datasets**

The [**Tokenizers & Datasets**](https://github.com/ThinamXx/Transformers_NLP/blob/main/01.%20Transformers%20for%20NLP/08.%20Tokenizers%20%26%20Datasets/Tokenizers%26Datasets.ipynb) notebook contains information about Preprocessing and Postprocessing, Tokenization, Training Word2Vec Model, Cosine Similarity, Trained Unconditional Samples and Transformer Models such as T5 and GPT. 

**Note:**
- üìù[**Tokenizers & Datasets**](https://github.com/ThinamXx/Transformers_NLP/blob/main/01.%20Transformers%20for%20NLP/08.%20Tokenizers%20%26%20Datasets/Tokenizers%26Datasets.ipynb)

**Preprocessing**
- Sentences with punctuation marks.
- Remove bad words.
- Remove code.
- Removing references to discrimination.
- Logic check.
- Bad information reference.

**Postprocessing**
- Checking input in real time.
- Real time messages.
- Language conversions.
- Privacy checks.
