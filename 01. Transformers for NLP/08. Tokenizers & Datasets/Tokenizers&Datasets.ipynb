{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenizers&Datasets.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Initialization**\n",
        "- I use these three lines of code on top of my each notebooks because it will help to prevent any problems while reloading the same project. And the third line of code helps to make visualization within the notebook."
      ],
      "metadata": {
        "id": "iSmganLBCoFm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e9kGbQcZA0SP"
      },
      "outputs": [],
      "source": [
        "#@ INITIALIZATION: \n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Downloading Libraries and Dependencies**\n",
        "- I have downloaded all the libraries and dependencies required for the project in one particular cell."
      ],
      "metadata": {
        "id": "SHgs5BjwFVJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ IMPORTING MODULES: UNCOMMENT BELOW:\n",
        "# !pip install --upgrade gensim\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#@ IGNORING WARNINGS: \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR5ORMWaFeNG",
        "outputId": "a528776c-4a1c-4bec-c02d-4045ec90d68e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Preprocessing**\n",
        " - Sentences with punctuation marks.\n",
        " - Remove bad words.\n",
        " - Remove code. \n",
        " - Removing references to discrimination. \n",
        " - Logic check.\n",
        " - Bad information reference. "
      ],
      "metadata": {
        "id": "02vlJN9eC6i7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Postprocessing**\n",
        " - Checking input in real time. \n",
        " - Real time messages.\n",
        " - Language conversions. \n",
        " - Privacy checks. "
      ],
      "metadata": {
        "id": "ammG7ysBFg-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization and Training**"
      ],
      "metadata": {
        "id": "BLQn7-7XGygq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ WORD2VEC TOKENIZATION AND TRAINING:\n",
        "sample = open(\"text.txt\", \"r\")                          # Reading the dataset.\n",
        "s = sample.read()                                       # Reading the dataset.\n",
        "f = s.replace(\"\\n\", \" \")                                # Processing escape characters. \n",
        "data = []                                               # Initialization.\n",
        "for i in sent_tokenize(f):\n",
        "    tmp = []                                            # Initialization.\n",
        "    for j in word_tokenize(i):\n",
        "        tmp.append(j.lower())\n",
        "    data.append(tmp)                                    # Updating data list.\n",
        "\n",
        "#@ CREATING SKIP GRAM MODEL:\n",
        "model = Word2Vec(data, min_count=1, vector_size=512, \n",
        "                 window=5, sg=1)                        # Initializing Word2Vec model. \n",
        "print(model)                                            # Inspecting model."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gelRvc54HLay",
        "outputId": "38baa4b1-9952-47a5-d49a-86dde5e539a9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec(vocab=11822, vector_size=512, alpha=0.025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cosine Similarity**"
      ],
      "metadata": {
        "id": "UY3CMfMLKTOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ INITIALIZING COSINE SIMILARITY:\n",
        "def similarity(word1, word2):                           # Defining function.\n",
        "    cosine = False                                      # Default value.\n",
        "    try:\n",
        "        a = model.wv[word1]                             # Implementation of Word2Vec. \n",
        "        cosine = True\n",
        "    except KeyError:\n",
        "        print(word1, \":[unk] key not in dictionary\")\n",
        "    try:\n",
        "        b = model.wv[word2]                             # Implementation of Word2Vec. \n",
        "    except KeyError:\n",
        "        cosine = False\n",
        "        print(word1, \":[unk] key not in dictionary\")\n",
        "    if cosine:\n",
        "        b = model.wv[word2]\n",
        "        dot = np.dot(a, b)                              # Initializing dot product. \n",
        "        norma = np.linalg.norm(a)                       # Normalized value.\n",
        "        normb = np.linalg.norm(b)                       # Normalized value. \n",
        "        cos = dot / (norma * normb)\n",
        "        aa = a.reshape(1, 512)                          # Reshaping.\n",
        "        bb = b.reshape(1, 512)                          # Reshaping.\n",
        "        cos_lib = cosine_similarity(aa, bb)             # Cosine similarity. \n",
        "    if cosine == False:\n",
        "        cos_lib = 0\n",
        "    return cos_lib                                      # Getting cosine similarity. "
      ],
      "metadata": {
        "id": "VOzCkjfnJXhl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Case 0: Words in Dataset and Dictionary**"
      ],
      "metadata": {
        "id": "Tq0MiX83M-hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ CASE 0: WORDS IN DATASET AND DICTIONARY:\n",
        "word1 = \"freedom\"                                       # Initialization. \n",
        "word2 = \"liberty\"                                       # Initialization. \n",
        "print(\"Similarity:\", similarity(word1, word2), \n",
        "      word1, word2)                                     # Inspecting cosine similarity."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzR5m2SaM5mB",
        "outputId": "4b376ce7-53bc-48e4-bb54-b526e085cb38"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: [[0.33997628]] freedom liberty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Case 1: Words not in Dataset and Dictionary**"
      ],
      "metadata": {
        "id": "LC8v0ctSO8gC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ CASE 1: WORDS NOT IN DATASET AND DICTIONARY:\n",
        "word1 = \"corporations\"                                  # Initialization. \n",
        "word2 = \"rights\"                                        # Initialization. \n",
        "print(\"Similarity:\", similarity(word1, word2), \n",
        "      word1, word2)                                     # Inspecting cosine similarity."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjjofNpJNpJV",
        "outputId": "53089561-92cd-4e50-975b-0f739501b4b5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corporations :[unk] key not in dictionary\n",
            "Similarity: 0 corporations rights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Case 2: Noisy Relationships**"
      ],
      "metadata": {
        "id": "jMXppKs2RIBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ CASE 2: NOISY RELATIONSHIPS:\n",
        "word1 = \"etext\"                                         # Initialization. \n",
        "word2 = \"declaration\"                                   # Initialization. \n",
        "print(\"Similarity:\", similarity(word1, word2), \n",
        "      word1, word2)                                     # Inspecting cosine similarity."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H1uolJlPJ62",
        "outputId": "95c8503e-da00-4e99-f6a3-fa5c6dcbb677"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: [[0.56526434]] etext declaration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Case 3: Rare Words**"
      ],
      "metadata": {
        "id": "NnuzshE-SLMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ CASE 3: RARE WORDS:\n",
        "word1 = \"justiciar\"                                     # Initialization. \n",
        "word2 = \"judgement\"                                     # Initialization. \n",
        "print(\"Similarity:\", similarity(word1, word2), \n",
        "      word1, word2)                                     # Inspecting cosine similarity."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mSscq7zRivL",
        "outputId": "ce3d7b31-6f3b-463b-a849-956c6fd20efe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: [[0.24473113]] justiciar judgement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Case 4: Replacing Rare Words**"
      ],
      "metadata": {
        "id": "wZNG8mAITARY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ CASE 3: REPLACING RARE WORDS:\n",
        "word1 = \"judge\"                                         # Initialization. \n",
        "word2 = \"judgement\"                                     # Initialization. \n",
        "print(\"Similarity:\", similarity(word1, word2), \n",
        "      word1, word2)                                     # Inspecting cosine similarity."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8vViBf2Sb2R",
        "outputId": "766cf21f-2d71-4a6c-d58a-f2a383c04bd5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: [[0.16116652]] judge judgement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ CASE 3: REPLACING RARE WORDS:\n",
        "word1 = \"judge\"                                         # Initialization. \n",
        "word2 = \"justiciar\"                                     # Initialization. \n",
        "print(\"Similarity:\", similarity(word1, word2), \n",
        "      word1, word2)                                     # Inspecting cosine similarity."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OJF9msIXEjY",
        "outputId": "bc6451cf-6417-49b7-c547-30a1c47beea6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: [[0.32938716]] judge justiciar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Case 5: Entailment**"
      ],
      "metadata": {
        "id": "0rWIq4Z5X0Zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ CASE 5: ENTAILMENT:\n",
        "word1 = \"pay\"                                           # Initialization. \n",
        "word2 = \"debt\"                                          # Initialization. \n",
        "print(\"Similarity:\", similarity(word1, word2), \n",
        "      word1, word2)                                     # Inspecting cosine similarity."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS-ik8iJXnpI",
        "outputId": "4e36291d-8cc4-43b0-a61b-2186dedbd9be"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity: [[0.52598727]] pay debt\n"
          ]
        }
      ]
    }
  ]
}