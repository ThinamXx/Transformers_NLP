{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md66tku5Gz8R"
      },
      "source": [
        "**Initialization**\n",
        "- I use these three lines of code on top of my each notebooks because it will help to prevent any problems while reloading the same project. And the third line of code helps to make visualization within the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k210Am9dFZsX"
      },
      "outputs": [],
      "source": [
        "#@ INITIALIZATION: \n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26XwuevrHHWK"
      },
      "source": [
        "**Downloading Libraries and Dependencies**\n",
        "- I have downloaded all the libraries and dependencies required for the project in one particular cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ah_l4i17HEqP"
      },
      "outputs": [],
      "source": [
        "#@ IMPORTING MODULES: UNCOMMENT BELOW:\n",
        "# !pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
        "\n",
        "#@ IGNORING WARNINGS: \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imAqEXSxJF3d"
      },
      "source": [
        "**SRL EXPERIMENTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh7L-1FYHgdY",
        "outputId": "13ed0975-a618-4fdd-ea3f-2b328ed840cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-13 10:51:19,363 - INFO - transformers.file_utils - PyTorch version 1.5.1 available.\n",
            "2022-04-13 10:51:24,514 - INFO - numexpr.utils - NumExpr defaulting to 2 threads.\n",
            "2022-04-13 10:51:25,441 - INFO - transformers.file_utils - TensorFlow version 2.8.0 available.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "2022-04-13 10:51:28,598 - INFO - allennlp.common.file_utils - checking cache for https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2022-04-13 10:51:28,598 - INFO - allennlp.common.file_utils - waiting to acquire lock on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2022-04-13 10:51:28,599 - INFO - filelock - Lock 140029120367376 acquired on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2022-04-13 10:51:28,599 - INFO - allennlp.common.file_utils - https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz not found in cache, downloading to /root/.allennlp/cache/tmphinhdlpw.tmp\n",
            "100% 406056588/406056588 [00:08<00:00, 50358419.57B/s]\n",
            "2022-04-13 10:51:36,816 - INFO - allennlp.common.file_utils - Renaming temp file /root/.allennlp/cache/tmphinhdlpw.tmp to cache at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2022-04-13 10:51:36,816 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2022-04-13 10:51:36,816 - INFO - filelock - Lock 140029120367376 released on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2022-04-13 10:51:36,816 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz from cache at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2022-04-13 10:51:36,817 - INFO - allennlp.models.archival - extracting archive file /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724 to temp dir /tmp/tmp6b06mx5d\n",
            "2022-04-13 10:51:41,312 - INFO - allennlp.common.params - type = from_instances\n",
            "2022-04-13 10:51:41,312 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmp6b06mx5d/vocabulary.\n",
            "2022-04-13 10:51:41,312 - INFO - filelock - Lock 140029106509136 acquired on /tmp/tmp6b06mx5d/vocabulary/.lock\n",
            "2022-04-13 10:51:41,349 - INFO - filelock - Lock 140029106509136 released on /tmp/tmp6b06mx5d/vocabulary/.lock\n",
            "2022-04-13 10:51:41,349 - INFO - allennlp.common.params - model.type = srl_bert\n",
            "2022-04-13 10:51:41,350 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2022-04-13 10:51:41,350 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
            "2022-04-13 10:51:41,350 - INFO - allennlp.common.params - model.embedding_dropout = 0.1\n",
            "2022-04-13 10:51:41,350 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f5b110ae590>\n",
            "2022-04-13 10:51:41,350 - INFO - allennlp.common.params - model.label_smoothing = None\n",
            "2022-04-13 10:51:41,350 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
            "2022-04-13 10:51:41,350 - INFO - allennlp.common.params - model.srl_eval_path = /usr/local/lib/python3.7/dist-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
            "2022-04-13 10:51:41,478 - INFO - filelock - Lock 140029088333776 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "2022-04-13 10:51:41,479 - INFO - transformers.file_utils - https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpzg2nourv\n",
            "Downloading: 100% 433/433 [00:00<00:00, 322kB/s]\n",
            "2022-04-13 10:51:41,595 - INFO - transformers.file_utils - storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json in cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2022-04-13 10:51:41,595 - INFO - transformers.file_utils - creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2022-04-13 10:51:41,595 - INFO - filelock - Lock 140029088333776 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "2022-04-13 10:51:41,595 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2022-04-13 10:51:41,596 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "2022-04-13 10:51:41,710 - INFO - filelock - Lock 140029088332880 acquired on /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "2022-04-13 10:51:41,710 - INFO - transformers.file_utils - https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp0t0bdbhb\n",
            "Downloading: 100% 440M/440M [00:08<00:00, 52.7MB/s]\n",
            "2022-04-13 10:51:50,142 - INFO - transformers.file_utils - storing https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2022-04-13 10:51:50,142 - INFO - transformers.file_utils - creating metadata file for /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2022-04-13 10:51:50,142 - INFO - filelock - Lock 140029088332880 released on /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "2022-04-13 10:51:50,142 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2022-04-13 10:51:53,343 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-04-13 10:51:53,345 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-04-13 10:51:53,345 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.bias\n",
            "2022-04-13 10:51:53,345 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.weight\n",
            "2022-04-13 10:51:53,345 - INFO - allennlp.nn.initializers -    bert_model.embeddings.position_embeddings.weight\n",
            "2022-04-13 10:51:53,345 - INFO - allennlp.nn.initializers -    bert_model.embeddings.token_type_embeddings.weight\n",
            "2022-04-13 10:51:53,345 - INFO - allennlp.nn.initializers -    bert_model.embeddings.word_embeddings.weight\n",
            "2022-04-13 10:51:53,345 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,345 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,345 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.bias\n",
            "2022-04-13 10:51:53,345 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.weight\n",
            "2022-04-13 10:51:53,345 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.bias\n",
            "2022-04-13 10:51:53,345 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.weight\n",
            "2022-04-13 10:51:53,345 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.bias\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.weight\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.bias\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.weight\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.bias\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.weight\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.bias\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.weight\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.bias\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.weight\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.bias\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.weight\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.bias\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.weight\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.bias\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.weight\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.bias\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.weight\n",
            "2022-04-13 10:51:53,346 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.bias\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.weight\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.bias\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.weight\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.bias\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.weight\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.bias\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.weight\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.bias\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.weight\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.bias\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.weight\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.bias\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.weight\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.bias\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.weight\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.bias\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.weight\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.bias\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.weight\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.bias\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.weight\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.bias\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.weight\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.bias\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.weight\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.bias\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.weight\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.bias\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.weight\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.bias\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.weight\n",
            "2022-04-13 10:51:53,348 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.bias\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.weight\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.bias\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.weight\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.bias\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.weight\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.bias\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.weight\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.bias\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.weight\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.bias\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.weight\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.bias\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.weight\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.bias\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.weight\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,349 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.bias\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.weight\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.bias\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.weight\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.bias\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.weight\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.bias\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.weight\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.bias\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.weight\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.bias\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.weight\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.bias\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.weight\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.bias\n",
            "2022-04-13 10:51:53,350 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.weight\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.bias\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.weight\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.bias\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.weight\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.bias\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.weight\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.bias\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.weight\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.bias\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.weight\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.bias\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.weight\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.bias\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.weight\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.bias\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.weight\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.bias\n",
            "2022-04-13 10:51:53,351 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.weight\n",
            "2022-04-13 10:51:53,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.bias\n",
            "2022-04-13 10:51:53,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.weight\n",
            "2022-04-13 10:51:53,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.bias\n",
            "2022-04-13 10:51:53,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.weight\n",
            "2022-04-13 10:51:53,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.bias\n",
            "2022-04-13 10:51:53,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.weight\n",
            "2022-04-13 10:51:53,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.bias\n",
            "2022-04-13 10:51:53,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.weight\n",
            "2022-04-13 10:51:53,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.bias\n",
            "2022-04-13 10:51:53,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.weight\n",
            "2022-04-13 10:51:53,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.bias\n",
            "2022-04-13 10:51:53,358 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.weight\n",
            "2022-04-13 10:51:53,359 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.bias\n",
            "2022-04-13 10:51:53,359 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.weight\n",
            "2022-04-13 10:51:53,359 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,359 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,359 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.bias\n",
            "2022-04-13 10:51:53,359 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.weight\n",
            "2022-04-13 10:51:53,359 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,359 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,359 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.bias\n",
            "2022-04-13 10:51:53,359 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.weight\n",
            "2022-04-13 10:51:53,359 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.bias\n",
            "2022-04-13 10:51:53,359 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.weight\n",
            "2022-04-13 10:51:53,360 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.bias\n",
            "2022-04-13 10:51:53,360 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.weight\n",
            "2022-04-13 10:51:53,360 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.bias\n",
            "2022-04-13 10:51:53,360 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.weight\n",
            "2022-04-13 10:51:53,360 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.bias\n",
            "2022-04-13 10:51:53,360 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.weight\n",
            "2022-04-13 10:51:53,360 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,360 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,360 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.bias\n",
            "2022-04-13 10:51:53,360 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.weight\n",
            "2022-04-13 10:51:53,360 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,360 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,360 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.bias\n",
            "2022-04-13 10:51:53,360 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.weight\n",
            "2022-04-13 10:51:53,360 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.bias\n",
            "2022-04-13 10:51:53,361 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.weight\n",
            "2022-04-13 10:51:53,361 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.bias\n",
            "2022-04-13 10:51:53,361 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.weight\n",
            "2022-04-13 10:51:53,361 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.bias\n",
            "2022-04-13 10:51:53,361 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.weight\n",
            "2022-04-13 10:51:53,361 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.bias\n",
            "2022-04-13 10:51:53,361 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.weight\n",
            "2022-04-13 10:51:53,361 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2022-04-13 10:51:53,361 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2022-04-13 10:51:53,361 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.bias\n",
            "2022-04-13 10:51:53,361 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.weight\n",
            "2022-04-13 10:51:53,361 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.bias\n",
            "2022-04-13 10:51:53,361 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.weight\n",
            "2022-04-13 10:51:53,361 - INFO - allennlp.nn.initializers -    tag_projection_layer.bias\n",
            "2022-04-13 10:51:53,361 - INFO - allennlp.nn.initializers -    tag_projection_layer.weight\n",
            "2022-04-13 10:51:53,935 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
            "2022-04-13 10:51:53,936 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2022-04-13 10:51:53,936 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2022-04-13 10:51:53,936 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2022-04-13 10:51:53,936 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2022-04-13 10:51:53,936 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2022-04-13 10:51:53,936 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
            "2022-04-13 10:51:53,936 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
            "2022-04-13 10:51:53,936 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
            "2022-04-13 10:51:54,087 - INFO - filelock - Lock 140029107201488 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "2022-04-13 10:51:54,088 - INFO - transformers.file_utils - https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpth3af23t\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 2.78MB/s]\n",
            "2022-04-13 10:51:54,288 - INFO - transformers.file_utils - storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt in cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "2022-04-13 10:51:54,288 - INFO - transformers.file_utils - creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "2022-04-13 10:51:54,288 - INFO - filelock - Lock 140029107201488 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "2022-04-13 10:51:54,288 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "input 0:  {\"sentence\": \"Did Bob really think he could prepare a meal for 50 people in only a few hours?\"}\n",
            "prediction:  {\"verbs\": [{\"verb\": \"think\", \"description\": \"Did [ARG0: Bob] [ARGM-ADV: really] [V: think] [ARG1: he could prepare a meal for 50 people in only a few hours] ?\", \"tags\": [\"O\", \"B-ARG0\", \"B-ARGM-ADV\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\"]}, {\"verb\": \"could\", \"description\": \"Did Bob really think he [V: could] prepare a meal for 50 people in only a few hours ?\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"prepare\", \"description\": \"Did Bob really think [ARG0: he] [ARGM-MOD: could] [V: prepare] [ARG1: a meal for 50 people] [ARGM-TMP: in only a few hours] ?\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"B-ARG0\", \"B-ARGM-MOD\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"B-ARGM-TMP\", \"I-ARGM-TMP\", \"I-ARGM-TMP\", \"I-ARGM-TMP\", \"I-ARGM-TMP\", \"O\"]}], \"words\": [\"Did\", \"Bob\", \"really\", \"think\", \"he\", \"could\", \"prepare\", \"a\", \"meal\", \"for\", \"50\", \"people\", \"in\", \"only\", \"a\", \"few\", \"hours\", \"?\"]}\n",
            "\n",
            "2022-04-13 10:51:55,797 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmp6b06mx5d\n"
          ]
        }
      ],
      "source": [
        "#@ SAMPLE 1 OF SRL:\n",
        "!echo '{\"sentence\": \"Did Bob really think he could prepare a meal for 50 people in only a few hours?\"}' | \\\n",
        "allennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1Em2megSLdPN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fbfe9a-3fef-43df-913d-55ddf1397586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-13 10:55:34,350 - INFO - transformers.file_utils - PyTorch version 1.5.1 available.\n",
            "2022-04-13 10:55:36,765 - INFO - numexpr.utils - NumExpr defaulting to 2 threads.\n",
            "2022-04-13 10:55:37,346 - INFO - transformers.file_utils - TensorFlow version 2.8.0 available.\n",
            "2022-04-13 10:55:38,518 - INFO - allennlp.common.file_utils - checking cache for https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2022-04-13 10:55:38,518 - INFO - allennlp.common.file_utils - waiting to acquire lock on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2022-04-13 10:55:38,518 - INFO - filelock - Lock 140471346889936 acquired on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2022-04-13 10:55:38,518 - INFO - allennlp.common.file_utils - cache of https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz is up-to-date\n",
            "2022-04-13 10:55:38,518 - INFO - filelock - Lock 140471346889936 released on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2022-04-13 10:55:38,518 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz from cache at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2022-04-13 10:55:38,519 - INFO - allennlp.models.archival - extracting archive file /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724 to temp dir /tmp/tmpmnpm8jxa\n",
            "2022-04-13 10:55:42,948 - INFO - allennlp.common.params - type = from_instances\n",
            "2022-04-13 10:55:42,948 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpmnpm8jxa/vocabulary.\n",
            "2022-04-13 10:55:42,949 - INFO - filelock - Lock 140471339403728 acquired on /tmp/tmpmnpm8jxa/vocabulary/.lock\n",
            "2022-04-13 10:55:42,975 - INFO - filelock - Lock 140471339403728 released on /tmp/tmpmnpm8jxa/vocabulary/.lock\n",
            "2022-04-13 10:55:42,975 - INFO - allennlp.common.params - model.type = srl_bert\n",
            "2022-04-13 10:55:42,975 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2022-04-13 10:55:42,975 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
            "2022-04-13 10:55:42,976 - INFO - allennlp.common.params - model.embedding_dropout = 0.1\n",
            "2022-04-13 10:55:42,976 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7fc2082216d0>\n",
            "2022-04-13 10:55:42,976 - INFO - allennlp.common.params - model.label_smoothing = None\n",
            "2022-04-13 10:55:42,976 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
            "2022-04-13 10:55:42,976 - INFO - allennlp.common.params - model.srl_eval_path = /usr/local/lib/python3.7/dist-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
            "2022-04-13 10:55:43,126 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2022-04-13 10:55:43,127 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "2022-04-13 10:55:43,270 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2022-04-13 10:55:45,986 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-04-13 10:55:45,987 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-04-13 10:55:45,987 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.bias\n",
            "2022-04-13 10:55:45,987 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.weight\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.embeddings.position_embeddings.weight\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.embeddings.token_type_embeddings.weight\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.embeddings.word_embeddings.weight\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.bias\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.weight\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.bias\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.weight\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.bias\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.weight\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.bias\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.weight\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.bias\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.weight\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.bias\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.weight\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,988 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.bias\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.weight\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.bias\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.weight\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.bias\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.weight\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.bias\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.weight\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.bias\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.weight\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.bias\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.weight\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.bias\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.weight\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.bias\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.weight\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.bias\n",
            "2022-04-13 10:55:45,989 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.weight\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.bias\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.weight\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.bias\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.weight\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.bias\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.weight\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.bias\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.weight\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.bias\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.weight\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.bias\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.weight\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.bias\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.weight\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.bias\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.weight\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.bias\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.weight\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.bias\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.weight\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.bias\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.weight\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.bias\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.weight\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.bias\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.weight\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.bias\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.weight\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.bias\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.weight\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.bias\n",
            "2022-04-13 10:55:45,991 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.weight\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.bias\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.weight\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.bias\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.weight\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.bias\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.weight\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.bias\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.weight\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.bias\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.weight\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.bias\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.weight\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.bias\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.weight\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.bias\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.weight\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.bias\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.weight\n",
            "2022-04-13 10:55:45,992 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.bias\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.weight\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.bias\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.weight\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.bias\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.weight\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.bias\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.weight\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.bias\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.weight\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.bias\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.weight\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.bias\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.weight\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.bias\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.weight\n",
            "2022-04-13 10:55:45,993 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.bias\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.weight\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.bias\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.weight\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.bias\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.weight\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.bias\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.weight\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.bias\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.weight\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.bias\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.weight\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.bias\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.weight\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.bias\n",
            "2022-04-13 10:55:45,994 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.weight\n",
            "2022-04-13 10:55:45,995 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.bias\n",
            "2022-04-13 10:55:45,995 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.weight\n",
            "2022-04-13 10:55:45,995 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.bias\n",
            "2022-04-13 10:55:46,053 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.weight\n",
            "2022-04-13 10:55:46,053 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.bias\n",
            "2022-04-13 10:55:46,053 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.weight\n",
            "2022-04-13 10:55:46,053 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2022-04-13 10:55:46,053 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2022-04-13 10:55:46,053 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.bias\n",
            "2022-04-13 10:55:46,053 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.weight\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.bias\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.weight\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.bias\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.weight\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.bias\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.weight\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.bias\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.weight\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.bias\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.weight\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.bias\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.weight\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.bias\n",
            "2022-04-13 10:55:46,054 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.weight\n",
            "2022-04-13 10:55:46,055 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.bias\n",
            "2022-04-13 10:55:46,055 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.weight\n",
            "2022-04-13 10:55:46,055 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.bias\n",
            "2022-04-13 10:55:46,055 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.weight\n",
            "2022-04-13 10:55:46,055 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.bias\n",
            "2022-04-13 10:55:46,055 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.weight\n",
            "2022-04-13 10:55:46,055 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.bias\n",
            "2022-04-13 10:55:46,055 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.weight\n",
            "2022-04-13 10:55:46,055 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2022-04-13 10:55:46,055 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2022-04-13 10:55:46,055 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.bias\n",
            "2022-04-13 10:55:46,055 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.weight\n",
            "2022-04-13 10:55:46,055 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.bias\n",
            "2022-04-13 10:55:46,055 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.weight\n",
            "2022-04-13 10:55:46,055 - INFO - allennlp.nn.initializers -    tag_projection_layer.bias\n",
            "2022-04-13 10:55:46,055 - INFO - allennlp.nn.initializers -    tag_projection_layer.weight\n",
            "2022-04-13 10:55:46,597 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
            "2022-04-13 10:55:46,597 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2022-04-13 10:55:46,597 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2022-04-13 10:55:46,597 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2022-04-13 10:55:46,597 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2022-04-13 10:55:46,597 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2022-04-13 10:55:46,597 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
            "2022-04-13 10:55:46,597 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
            "2022-04-13 10:55:46,597 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
            "2022-04-13 10:55:46,705 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "input 0:  {\"sentence\": \"Mrs. And Mr. Tomaso went to Europe for vacation and visited Paris and first went to visit the Eiffel Tower.\"}\n",
            "prediction:  {\"verbs\": [{\"verb\": \"went\", \"description\": \"[ARG0: Mrs. And Mr. Tomaso] [V: went] [ARG4: to Europe] [ARGM-PRP: for vacation] and visited Paris and first went to visit the Eiffel Tower .\", \"tags\": [\"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"B-V\", \"B-ARG4\", \"I-ARG4\", \"B-ARGM-PRP\", \"I-ARGM-PRP\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"visited\", \"description\": \"[ARG0: Mrs. And Mr. Tomaso] went to Europe for vacation and [V: visited] [ARG1: Paris] and first went to visit the Eiffel Tower .\", \"tags\": [\"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARG1\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"went\", \"description\": \"[ARG0: Mrs. And Mr. Tomaso] went to Europe for vacation and visited Paris and [ARGM-TMP: first] [V: went] [ARGM-PRP: to visit the Eiffel Tower] .\", \"tags\": [\"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ARGM-TMP\", \"B-V\", \"B-ARGM-PRP\", \"I-ARGM-PRP\", \"I-ARGM-PRP\", \"I-ARGM-PRP\", \"I-ARGM-PRP\", \"O\"]}, {\"verb\": \"visit\", \"description\": \"[ARG0: Mrs. And Mr. Tomaso] went to Europe for vacation and visited Paris and first went to [V: visit] [ARG1: the Eiffel Tower] .\", \"tags\": [\"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\"]}], \"words\": [\"Mrs.\", \"And\", \"Mr.\", \"Tomaso\", \"went\", \"to\", \"Europe\", \"for\", \"vacation\", \"and\", \"visited\", \"Paris\", \"and\", \"first\", \"went\", \"to\", \"visit\", \"the\", \"Eiffel\", \"Tower\", \".\"]}\n",
            "\n",
            "2022-04-13 10:55:48,276 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpmnpm8jxa\n"
          ]
        }
      ],
      "source": [
        "#@ SAMPLE 2 OF SRL:\n",
        "!echo '{\"sentence\": \"Mrs. And Mr. Tomaso went to Europe for vacation and visited Paris and first went to visit the Eiffel Tower.\"}' | \\\n",
        "allennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz -"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ SAMPLE 3 OF SRL:\n",
        "!echo '{\"sentence\": \"John wanted to drink tea, Mary likes to drink coffee but Karim drank some cool water and Faiza would like to drink tomato juice.\"}' | \\\n",
        "allennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz -"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mIMDwSpkHN1",
        "outputId": "84b2f41c-9937-4201-9d3c-060303c1f3aa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-13 10:58:42,169 - INFO - transformers.file_utils - PyTorch version 1.5.1 available.\n",
            "2022-04-13 10:58:45,564 - INFO - numexpr.utils - NumExpr defaulting to 2 threads.\n",
            "2022-04-13 10:58:46,128 - INFO - transformers.file_utils - TensorFlow version 2.8.0 available.\n",
            "2022-04-13 10:58:47,422 - INFO - allennlp.common.file_utils - checking cache for https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2022-04-13 10:58:47,422 - INFO - allennlp.common.file_utils - waiting to acquire lock on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2022-04-13 10:58:47,423 - INFO - filelock - Lock 139922744605776 acquired on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2022-04-13 10:58:47,423 - INFO - allennlp.common.file_utils - cache of https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz is up-to-date\n",
            "2022-04-13 10:58:47,423 - INFO - filelock - Lock 139922744605776 released on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2022-04-13 10:58:47,423 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz from cache at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2022-04-13 10:58:47,423 - INFO - allennlp.models.archival - extracting archive file /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724 to temp dir /tmp/tmpygkf9t0p\n",
            "2022-04-13 10:58:53,060 - INFO - allennlp.common.params - type = from_instances\n",
            "2022-04-13 10:58:53,060 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpygkf9t0p/vocabulary.\n",
            "2022-04-13 10:58:53,061 - INFO - filelock - Lock 139922730723280 acquired on /tmp/tmpygkf9t0p/vocabulary/.lock\n",
            "2022-04-13 10:58:53,098 - INFO - filelock - Lock 139922730723280 released on /tmp/tmpygkf9t0p/vocabulary/.lock\n",
            "2022-04-13 10:58:53,099 - INFO - allennlp.common.params - model.type = srl_bert\n",
            "2022-04-13 10:58:53,100 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2022-04-13 10:58:53,100 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
            "2022-04-13 10:58:53,100 - INFO - allennlp.common.params - model.embedding_dropout = 0.1\n",
            "2022-04-13 10:58:53,100 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f424c8d9710>\n",
            "2022-04-13 10:58:53,100 - INFO - allennlp.common.params - model.label_smoothing = None\n",
            "2022-04-13 10:58:53,100 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
            "2022-04-13 10:58:53,100 - INFO - allennlp.common.params - model.srl_eval_path = /usr/local/lib/python3.7/dist-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
            "2022-04-13 10:58:53,235 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2022-04-13 10:58:53,236 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "2022-04-13 10:58:53,358 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2022-04-13 10:58:57,231 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2022-04-13 10:58:57,232 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2022-04-13 10:58:57,232 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.bias\n",
            "2022-04-13 10:58:57,232 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.weight\n",
            "2022-04-13 10:58:57,232 - INFO - allennlp.nn.initializers -    bert_model.embeddings.position_embeddings.weight\n",
            "2022-04-13 10:58:57,232 - INFO - allennlp.nn.initializers -    bert_model.embeddings.token_type_embeddings.weight\n",
            "2022-04-13 10:58:57,232 - INFO - allennlp.nn.initializers -    bert_model.embeddings.word_embeddings.weight\n",
            "2022-04-13 10:58:57,232 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,232 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,232 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.bias\n",
            "2022-04-13 10:58:57,232 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.weight\n",
            "2022-04-13 10:58:57,232 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.bias\n",
            "2022-04-13 10:58:57,232 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.weight\n",
            "2022-04-13 10:58:57,232 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.bias\n",
            "2022-04-13 10:58:57,232 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.weight\n",
            "2022-04-13 10:58:57,232 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.bias\n",
            "2022-04-13 10:58:57,232 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.bias\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.bias\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.bias\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.bias\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.bias\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.bias\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.bias\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.bias\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.bias\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.bias\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.bias\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.bias\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.bias\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.weight\n",
            "2022-04-13 10:58:57,233 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.weight\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.weight\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.weight\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.weight\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.weight\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.weight\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.weight\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.weight\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.weight\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.weight\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.weight\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.weight\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.bias\n",
            "2022-04-13 10:58:57,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.bias\n",
            "2022-04-13 10:58:57,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.weight\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.bias\n",
            "2022-04-13 10:58:57,236 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.weight\n",
            "2022-04-13 10:58:57,237 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.bias\n",
            "2022-04-13 10:58:57,249 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.weight\n",
            "2022-04-13 10:58:57,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.bias\n",
            "2022-04-13 10:58:57,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.weight\n",
            "2022-04-13 10:58:57,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.bias\n",
            "2022-04-13 10:58:57,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.weight\n",
            "2022-04-13 10:58:57,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.bias\n",
            "2022-04-13 10:58:57,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.weight\n",
            "2022-04-13 10:58:57,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.bias\n",
            "2022-04-13 10:58:57,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.weight\n",
            "2022-04-13 10:58:57,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.bias\n",
            "2022-04-13 10:58:57,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.weight\n",
            "2022-04-13 10:58:57,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.bias\n",
            "2022-04-13 10:58:57,250 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.weight\n",
            "2022-04-13 10:58:57,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.bias\n",
            "2022-04-13 10:58:57,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.weight\n",
            "2022-04-13 10:58:57,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.bias\n",
            "2022-04-13 10:58:57,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.weight\n",
            "2022-04-13 10:58:57,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.bias\n",
            "2022-04-13 10:58:57,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.weight\n",
            "2022-04-13 10:58:57,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.bias\n",
            "2022-04-13 10:58:57,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.weight\n",
            "2022-04-13 10:58:57,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.bias\n",
            "2022-04-13 10:58:57,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.weight\n",
            "2022-04-13 10:58:57,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.bias\n",
            "2022-04-13 10:58:57,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.weight\n",
            "2022-04-13 10:58:57,251 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.bias\n",
            "2022-04-13 10:58:57,252 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.weight\n",
            "2022-04-13 10:58:57,252 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2022-04-13 10:58:57,252 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2022-04-13 10:58:57,252 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.bias\n",
            "2022-04-13 10:58:57,252 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.weight\n",
            "2022-04-13 10:58:57,252 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.bias\n",
            "2022-04-13 10:58:57,252 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.weight\n",
            "2022-04-13 10:58:57,252 - INFO - allennlp.nn.initializers -    tag_projection_layer.bias\n",
            "2022-04-13 10:58:57,252 - INFO - allennlp.nn.initializers -    tag_projection_layer.weight\n",
            "2022-04-13 10:58:58,239 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
            "2022-04-13 10:58:58,240 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2022-04-13 10:58:58,240 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2022-04-13 10:58:58,240 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2022-04-13 10:58:58,240 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2022-04-13 10:58:58,240 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2022-04-13 10:58:58,240 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
            "2022-04-13 10:58:58,240 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
            "2022-04-13 10:58:58,240 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
            "2022-04-13 10:58:58,373 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "input 0:  {\"sentence\": \"John wanted to drink tea, Mary likes to drink coffee but Karim drank some cool water and Faiza would like to drink tomato juice.\"}\n",
            "prediction:  {\"verbs\": [{\"verb\": \"wanted\", \"description\": \"[ARG0: John] [V: wanted] [ARG1: to drink tea] , Mary likes to drink coffee but Karim drank some cool water and Faiza would like to drink tomato juice .\", \"tags\": [\"B-ARG0\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"drink\", \"description\": \"[ARG0: John] wanted to [V: drink] [ARG1: tea] , Mary likes to drink coffee but Karim drank some cool water and Faiza would like to drink tomato juice .\", \"tags\": [\"B-ARG0\", \"O\", \"O\", \"B-V\", \"B-ARG1\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"likes\", \"description\": \"John wanted to drink tea , [ARG0: Mary] [V: likes] [ARG1: to drink coffee] but Karim drank some cool water and Faiza would like to drink tomato juice .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ARG0\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"drink\", \"description\": \"John wanted to drink tea , [ARG0: Mary] likes to [V: drink] [ARG1: coffee] but Karim drank some cool water and Faiza would like to drink tomato juice .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ARG0\", \"O\", \"O\", \"B-V\", \"B-ARG1\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"drank\", \"description\": \"John wanted to drink tea , Mary likes to drink coffee but [ARG0: Karim] [V: drank] [ARG1: some cool water and Faiza] would like to drink tomato juice .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ARG0\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"would\", \"description\": \"John wanted to drink tea , Mary likes to drink coffee but Karim drank some cool water and Faiza [V: would] [ARGM-DIS: like] to drink tomato juice .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARGM-DIS\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"like\", \"description\": \"John wanted to drink tea , Mary likes to drink coffee but Karim drank [ARG0: some cool water and Faiza] [ARGM-MOD: would] [V: like] [ARG1: to drink tomato juice] .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"B-ARGM-MOD\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\"]}, {\"verb\": \"drink\", \"description\": \"John wanted to drink tea , Mary likes to drink coffee but Karim drank [ARG0: some cool water and Faiza] would like to [V: drink] [ARG1: tomato juice] .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"O\"]}], \"words\": [\"John\", \"wanted\", \"to\", \"drink\", \"tea\", \",\", \"Mary\", \"likes\", \"to\", \"drink\", \"coffee\", \"but\", \"Karim\", \"drank\", \"some\", \"cool\", \"water\", \"and\", \"Faiza\", \"would\", \"like\", \"to\", \"drink\", \"tomato\", \"juice\", \".\"]}\n",
            "\n",
            "2022-04-13 10:59:00,496 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpygkf9t0p\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SemanticRoleLabeling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}