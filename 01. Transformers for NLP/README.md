# **TRANSFORMERS FOR NATURAL LANGUAGE PROCESSING**

The repository contains a list of the projects and notebooks which we have worked on while reading the book **Transformers for Natural Language Processing**.

## **ðŸ“šNOTEBOOKS:**

[**1. TRANSFORMER ARCHITECTURE**](https://github.com/ThinamXx/Transformers_NLP/tree/main/01.%20Transformers%20for%20NLP/01.%20Transformer%20Architecture) 
- The **Positional Encoding** notebook contains information about Positional Encoding, Word Embeddings and Positional Vectors. The **Transformer Architecture** notebook contains information about Input Embedding, Multi-head Attention, Weight Matrices, Matrix Multiplication and Attention Representations.

[**2. FINE-TUNING BERT MODEL**](https://github.com/ThinamXx/Transformers_NLP/tree/main/01.%20Transformers%20for%20NLP/02.%20Fine-Tuning%20BERT%20Model)
- The **BERT** notebook contains information about BERT Architecture, Processing Dataset, BERT Tokenizer, Attention Masks, BERT Model Configuration, Optimizer Grouped Parameters, Initializing Hyperparameters, Tranining & Evaluation and Matthews Correlation Coefficient.

[**3. PRETRAINING ROBERTA MODEL**](https://github.com/ThinamXx/Transformers_NLP/tree/main/01.%20Transformers%20for%20NLP/03.%20Pretraining%20RoBERTa%20Model)
- The **RoBERTa** Model notebook contains information about Loading Dataset, Training a Tokenizer, Saving & Loading Trained Tokenizer, Model Configurations, Model Parameters, Data Collator, Transformer Trainer and Pretraining Language Modeling.

[**4. NLP TASKS WITH TRANSFORMERS**](https://github.com/ThinamXx/Transformers_NLP/tree/main/01.%20Transformers%20for%20NLP/04.%20NLP%20Tasks%20with%20Transformers) 
- The **Transformers** notebook contains information about Transformers, Corpus of Linguistic Acceptability, Stanford Sentiment Treebank, Microsoft Research Paraphrase Corpus and Winograd Schemas.

[**5. MACHINE TRANSLATION**](https://github.com/ThinamXx/Transformers_NLP/tree/main/01.%20Transformers%20for%20NLP/05.%20Machine%20Translation) 
- The **Machine Translation** notebook contains information about Machine Translation, Preprocessing Dataset, Vocabulary & OOV Words, Bilingual Evaluation Understudy Score, Trax & Transformer Model, Tokenization and Decoding.

[**6. TEXT GENERATION WITH GPT-2**](https://github.com/ThinamXx/Transformers_NLP/tree/main/01.%20Transformers%20for%20NLP/06.%20Text%20Generation%20GPT-2)
- The **GPT2 Model** notebook contains information about OpenAI GPT2 Model, Encoding and Training GPT2 Model, Transformers, Reformers, PET, Text Completion and Language Models.

[**7. T5 MODEL**](https://github.com/ThinamXx/Transformers_NLP/blob/main/01.%20Transformers%20for%20NLP/07.%20Summarization%20with%20T5/T5Model.ipynb)
- The T5 Model notebook contains information about Architecture of T5 Model, Encoder and Decoder Blocks, Summarizing Documents with T5 Model and Transformer Models.

[**8. TOKENIZERS & DATASETS**](https://github.com/ThinamXx/Transformers_NLP/tree/main/01.%20Transformers%20for%20NLP/08.%20Tokenizers%20%26%20Datasets) 
- The **Tokenizers & Datasets** notebook contains information about Preprocessing and Postprocessing, Tokenization, Training Word2Vec Model, Cosine Similarity, Trained Unconditional Samples and Transformer Models such as T5 and GPT.

[**9. SEMANTIC ROLE LABELING**](https://github.com/ThinamXx/Transformers_NLP/tree/main/01.%20Transformers%20for%20NLP/09.%20Semantic%20Role%20Labeling)
- The **Semantic Role Labeling** notebook contains information about Semantic Role Labeling and BERT Transformer Model. SRL tasks are difficult for both humans and machines. BERT based transformer can perform predicate sense disambiguation.

[**10. QUESTION ANSWERING**](https://github.com/ThinamXx/Transformers_NLP/tree/main/01.%20Transformers%20for%20NLP/10.%20Question%20Answering)
- The **Question Answer** notebook contains information about Question Answering with Pretrained Transformer Model and Tokenizers, Semantic Role Labeling, Electra Model, Haystack and RoBERTa model.

[**11. SENTIMENT ANALYSIS**](https://github.com/ThinamXx/Transformers_NLP/tree/main/01.%20Transformers%20for%20NLP/11.%20Sentiment%20Analysis)
- The **Sentiment Analysis** notebook contains information about Sentiment Analysis with RoBERTa, DistilBERT, Stanford Sentiment Treebank, Compositionality and BERT-base Multilingual Model.
