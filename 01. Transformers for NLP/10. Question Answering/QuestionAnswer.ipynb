{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuestionAnswer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Initialization**\n",
        "- I use these three lines of code on top of my each notebooks because it will help to prevent any problems while reloading the same project. And the third line of code helps to make visualization within the notebook."
      ],
      "metadata": {
        "id": "7ScqE7JPT9WV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xO2YEcY5OYkb"
      },
      "outputs": [],
      "source": [
        "#@ INITIALIZATION: \n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Downloading Libraries and Dependencies**\n",
        "- I have downloaded all the libraries and dependencies required for the project in one particular cell."
      ],
      "metadata": {
        "id": "0DhiLW4HUIdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ IMPORTING MODULES: UNCOMMENT BELOW:\n",
        "# !pip install transformers\n",
        "# !pip install farm-haystack==0.6.0\n",
        "# !pip install urllib3==1.25.4\n",
        "import transformers\n",
        "from transformers import pipeline\n",
        "from haystack.reader.farm import FARMReader\n",
        "from haystack import Document\n",
        "\n",
        "#@ IGNORING WARNINGS: \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "WT27kuCHUEOV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trial and Error**"
      ],
      "metadata": {
        "id": "n_7H9VmjVBKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ QUESTION ANSWERING WITH DEFAULT MODEL AND TOKENIZER:\n",
        "nlp_qa = pipeline(\"question-answering\")                                    # Initializing QA model. \n",
        "sequence = \"The traffic began to slow down on Pioneer Boulevard in Los \\\n",
        "Angeles, making it difficult to get out of the city. However, WBGO was \\\n",
        "playing some cool jazz, and the weather was cool, making it rather \\\n",
        "pleasant to be making it out of the city on this Friday afternoon. Nat \\\n",
        "King Cole was singing as Jo and Maria slowly made their way out of LA \\\n",
        "and drove toward Barstow. They planned to get to Las Vegas early enough \\\n",
        "in the evening to have a nice dinner and go see a show.\"                   # Initializing a text. \n",
        "nlp_qa(context=sequence, question=\"Where is Pioneer Boulevard ?\")          # Implementation of model. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKWxW_lvUtpE",
        "outputId": "53c9dff4-7e0c-429d-aae0-0b04e648a20e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Los Angeles,', 'end': 67, 'score': 0.9879737496376038, 'start': 55}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NER First**"
      ],
      "metadata": {
        "id": "r0_IOesIt5xR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ NER WITH DEFAULT MODEL AND TOKENIZERS:\n",
        "nlp_ner = pipeline(\"ner\")                                                   # Initializing NER model.\n",
        "sequence = \"The traffic began to slow down on Pioneer Boulevard in Los \\\n",
        "Angeles, making it difficult to get out of the city. However, WBGO was \\\n",
        "playing some cool jazz, and the weather was cool, making it rather \\\n",
        "pleasant to be making it out of the city on this Friday afternoon. Nat \\\n",
        "King Cole was singing as Jo and Maria slowly made their way out of LA \\\n",
        "and drove toward Barstow. They planned to get to Las Vegas early enough \\\n",
        "in the evening to have a nice dinner and go see a show.\"                   # Initializing a text. \n",
        "nlp_ner(sequence)                                                          # Implementation of model."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzEY-fC3iVGK",
        "outputId": "ed982819-3557-4938-f399-59556f13d2bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'I-LOC',\n",
              "  'index': 8,\n",
              "  'score': 0.9735257029533386,\n",
              "  'word': 'Pioneer'},\n",
              " {'entity': 'I-LOC',\n",
              "  'index': 9,\n",
              "  'score': 0.9944824576377869,\n",
              "  'word': 'Boulevard'},\n",
              " {'entity': 'I-LOC', 'index': 11, 'score': 0.9995775818824768, 'word': 'Los'},\n",
              " {'entity': 'I-LOC',\n",
              "  'index': 12,\n",
              "  'score': 0.9995693564414978,\n",
              "  'word': 'Angeles'},\n",
              " {'entity': 'I-ORG', 'index': 26, 'score': 0.991984486579895, 'word': 'W'},\n",
              " {'entity': 'I-ORG', 'index': 27, 'score': 0.990750253200531, 'word': '##B'},\n",
              " {'entity': 'I-ORG', 'index': 28, 'score': 0.9884582161903381, 'word': '##G'},\n",
              " {'entity': 'I-ORG', 'index': 29, 'score': 0.9722681641578674, 'word': '##O'},\n",
              " {'entity': 'I-PER', 'index': 59, 'score': 0.9966881275177002, 'word': 'Nat'},\n",
              " {'entity': 'I-PER', 'index': 60, 'score': 0.997648298740387, 'word': 'King'},\n",
              " {'entity': 'I-PER', 'index': 61, 'score': 0.9986170530319214, 'word': 'Cole'},\n",
              " {'entity': 'I-PER', 'index': 65, 'score': 0.9978788495063782, 'word': 'Jo'},\n",
              " {'entity': 'I-PER',\n",
              "  'index': 67,\n",
              "  'score': 0.9988164901733398,\n",
              "  'word': 'Maria'},\n",
              " {'entity': 'I-LOC', 'index': 74, 'score': 0.998134434223175, 'word': 'LA'},\n",
              " {'entity': 'I-LOC', 'index': 78, 'score': 0.9970266819000244, 'word': 'Bar'},\n",
              " {'entity': 'I-LOC',\n",
              "  'index': 79,\n",
              "  'score': 0.8573915958404541,\n",
              "  'word': '##sto'},\n",
              " {'entity': 'I-LOC', 'index': 80, 'score': 0.9920249581336975, 'word': '##w'},\n",
              " {'entity': 'I-LOC', 'index': 87, 'score': 0.9993551969528198, 'word': 'Las'},\n",
              " {'entity': 'I-LOC',\n",
              "  'index': 88,\n",
              "  'score': 0.9989539384841919,\n",
              "  'word': 'Vegas'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ QUESTION ANSWERING WITH DEFAULT MODEL AND TOKENIZER:\n",
        "nlp_qa = pipeline(\"question-answering\")                                    # Initializing QA model. \n",
        "print(nlp_qa(context=sequence, question=\"Where is Pioneer Boulevard ?\"))   # Implementation of model. \n",
        "print(nlp_qa(context=sequence, question=\"Where is LosAngeles located?\"))   # Implementation of model. \n",
        "print(nlp_qa(context=sequence, question=\"Where is LA\"))                    # Implementation of model. \n",
        "print(nlp_qa(context=sequence, question=\"Where is Barstow\"))               # Implementation of model. \n",
        "print(nlp_qa(context=sequence, question=\"Where is Las Vegas located ?\"))   # Implementation of model. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIFK8TRPlrag",
        "outputId": "a8c50a83-4005-4ced-a32e-c10d87aeb75f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.9879737496376038, 'start': 55, 'end': 67, 'answer': 'Los Angeles,'}\n",
            "{'score': 0.4336349666118622, 'start': 55, 'end': 67, 'answer': 'Los Angeles,'}\n",
            "{'score': 0.3811359107494354, 'start': 34, 'end': 51, 'answer': 'Pioneer Boulevard'}\n",
            "{'score': 0.27760258316993713, 'start': 34, 'end': 51, 'answer': 'Pioneer Boulevard'}\n",
            "{'score': 0.21839775145053864, 'start': 355, 'end': 363, 'answer': 'Barstow.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ PERSON ENTITY QUESTIONS:\n",
        "nlp_qa = pipeline(\"question-answering\")                      # Initializing QA model. \n",
        "print(nlp_qa(context=sequence, question=\"Who is singing\"))   # Implementation of model. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reSFi8TWpcHd",
        "outputId": "58b5d6f6-6c90-40b4-eeec-65518deaea0d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.9718432426452637, 'start': 264, 'end': 277, 'answer': 'Nat King Cole'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ PERSON ENTITY QUESTIONS:\n",
        "nlp_qa = pipeline(\"question-answering\")                                    # Initializing QA model. \n",
        "print(nlp_qa(context=sequence, question=\"Who was going to Las Vegas ?\"))   # Implementation of model. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWrARYeruNqX",
        "outputId": "2bd160c1-71a9-4461-d6e9-570ce9c0caf5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.43162432312965393, 'start': 264, 'end': 277, 'answer': 'Nat King Cole'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SRL First**"
      ],
      "metadata": {
        "id": "ejKq-Rbpvugt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ PERSON ENTITY QUESTIONS:\n",
        "nlp_qa = pipeline(\"question-answering\")                                    # Initializing QA model. \n",
        "print(nlp_qa(context=sequence, question=\"Who are they?\"))                  # Implementation of model. "
      ],
      "metadata": {
        "id": "UDm3UnG4uoEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572da781-a745-4e84-bfde-8d1437deec40"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.8486900329589844, 'start': 293, 'end': 305, 'answer': 'Jo and Maria'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ PERSON ENTITY QUESTIONS:\n",
        "nlp_qa = pipeline(\"question-answering\")                                    # Initializing QA model. \n",
        "print(nlp_qa(context=sequence, question=\"Who drove to Las Vegas ?\"))       # Implementation of model. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaDluyljN_JP",
        "outputId": "553353fe-3ee8-461e-d203-98d7ddd3442a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.35941529273986816, 'start': 264, 'end': 305, 'answer': 'Nat King Cole was singing as Jo and Maria'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question Answering with Electra**"
      ],
      "metadata": {
        "id": "DqLV2ObyOGnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ INSPECTING THE MODEL:\n",
        "print(nlp_qa.model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pztmoOHHODzU",
        "outputId": "9728945c-153c-4fbf-e3eb-0fefe09b7e46"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBertForQuestionAnswering(\n",
            "  (distilbert): DistilBertModel(\n",
            "    (embeddings): Embeddings(\n",
            "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): Transformer(\n",
            "      (layer): ModuleList(\n",
            "        (0): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (1): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (2): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (3): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (4): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "        (5): TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ QUESTION ANSWERING WITH ELECTRA GENERATOR:\n",
        "nlp_qa = pipeline(\"question-answering\", model=\"google/electra-small-generator\",\n",
        "                  tokenizer=\"google/electra-small-generator\")                           # Initializing electra generator.\n",
        "nlp_qa(context=sequence, question=\"Who drove to Las Vegas?\")                            # Implementation of model."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRi7KdWnOfRb",
        "outputId": "75cd12ce-c3ee-4771-c279-85d4bcc0ba23"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/electra-small-generator were not used when initializing ElectraForQuestionAnswering: ['generator_predictions.LayerNorm.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.dense.weight', 'generator_predictions.dense.bias', 'generator_lm_head.weight', 'generator_lm_head.bias']\n",
            "- This IS expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at google/electra-small-generator and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'was cool, making it rather pleasant to be making',\n",
              " 'end': 218,\n",
              " 'score': 0.0002795897889882326,\n",
              " 'start': 170}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ PERSON ENTITY QUESTIONS:\n",
        "nlp_qa = pipeline(\"question-answering\")                                    # Initializing QA model. \n",
        "print(nlp_qa(context=sequence, question=\"Who sees a show?\"))               # Implementation of model. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_rwK3DeQau1",
        "outputId": "7057ee08-9e6e-4103-fdba-d3de0843d811"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.5588219165802002, 'start': 264, 'end': 277, 'answer': 'Nat King Cole'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ IMPLEMENTATION OF HAYSTACK:\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\",\n",
        "                    use_gpu=True, no_ans_boost=0, return_no_answer=False)       # Initializing pretrained model.\n",
        "doc = Document(text=sequence)                                                   # Initializing document. \n",
        "reader.predict(query=\"Where is Pioneer Boulevard located?\", documents=[doc])    # Inspection."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT2wE8NyTUGG",
        "outputId": "34b63dfc-65b0-4c9f-cf23-05b8b2fbac6a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "04/14/2022 09:17:06 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: None\n",
            "04/14/2022 09:17:06 - INFO - farm.infer -   Could not find `deepset/roberta-base-squad2` locally. Try to download from model hub ...\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "04/14/2022 09:17:12 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
            "\t We guess it's an *ENGLISH* model ... \n",
            "\t If not: Init the language model by supplying the 'language' param.\n",
            "04/14/2022 09:17:25 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: None\n",
            "04/14/2022 09:17:25 - INFO - farm.infer -   Got ya 1 parallel workers to do inference ...\n",
            "04/14/2022 09:17:25 - INFO - farm.infer -    0 \n",
            "04/14/2022 09:17:25 - INFO - farm.infer -   /w\\\n",
            "04/14/2022 09:17:25 - INFO - farm.infer -   /'\\\n",
            "04/14/2022 09:17:25 - INFO - farm.infer -   \n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.65 Batches/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answers': [{'answer': 'Los Angeles',\n",
              "   'context': 'The traffic began to slow down on Pioneer Boulevard in Los Angeles, making it difficult to get out of the city. However, WBGO was playing some cool ja',\n",
              "   'document_id': '347ef509-8993-443a-bdab-abb1c218f1bc',\n",
              "   'offset_end': 66,\n",
              "   'offset_end_in_doc': 66,\n",
              "   'offset_start': 55,\n",
              "   'offset_start_in_doc': 55,\n",
              "   'probability': 0.8022720407759694,\n",
              "   'score': 11.204444885253906}],\n",
              " 'no_ans_gap': 10.05623483657837,\n",
              " 'query': 'Where is Pioneer Boulevard located?'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ IMPLEMENTATION OF HAYSTACK:\n",
        "reader.predict(query=\"Who drove to Las Vegas?\", documents=[doc])     # Inspection."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTwriqXAWpD9",
        "outputId": "57612330-def9-4e88-8beb-5e4a65556e5f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 14.82 Batches/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answers': [{'answer': 'Jo and Maria',\n",
              "   'context': 't of the city on this Friday afternoon. Nat King Cole was singing as Jo and Maria slowly made their way out of LA and drove toward Barstow. They plann',\n",
              "   'document_id': '347ef509-8993-443a-bdab-abb1c218f1bc',\n",
              "   'offset_end': 81,\n",
              "   'offset_end_in_doc': 305,\n",
              "   'offset_start': 69,\n",
              "   'offset_start_in_doc': 293,\n",
              "   'probability': 0.8081117674150169,\n",
              "   'score': 11.502298355102539}],\n",
              " 'no_ans_gap': 3.783238410949707,\n",
              " 'query': 'Who drove to Las Vegas?'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}