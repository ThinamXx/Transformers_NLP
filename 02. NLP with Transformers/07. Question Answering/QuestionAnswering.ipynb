{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVyo_zwWnR9m"
      },
      "source": [
        "**Initialization**\n",
        "- I use these three lines of code on top of my each notebooks because it will help to prevent any problems while reloading the same project. And the third line of code helps to make visualization within the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjTYjrfHltkS"
      },
      "outputs": [],
      "source": [
        "#@ INITIALIZATION: \n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgmQqoZgoszC"
      },
      "source": [
        "**Downloading Libraries and Dependencies**\n",
        "- I have downloaded all the libraries and dependencies required for the project in one particular cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5FG_Bz_nYuh"
      },
      "outputs": [],
      "source": [
        "#@ IMPORTING MODULES: UNCOMMENT BELOW:\n",
        "# !pip install transformers[sentencepiece]\n",
        "# !pip install datasets\n",
        "# !pip install farm-haystack\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "from datasets import get_dataset_config_names\n",
        "from datasets import load_dataset\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "from haystack.document_stores import ElasticsearchDocumentStore\n",
        "from haystack.nodes import ElasticsearchRetriever\n",
        "from haystack.nodes import FARMReader\n",
        "from haystack.pipelines import ExtractiveQAPipeline\n",
        "from haystack.pipelines import Pipeline\n",
        "from haystack.nodes import EvalDocuments\n",
        "from haystack import Label\n",
        "\n",
        "#@ IGNORING WARNINGS: \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcfTWg1IpNp9"
      },
      "source": [
        "**The Dataset**\n",
        "- We will use **SubjQA** dataset which consists of more than 10,000 customer reviews in English about products and services."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZrs1rZ1pD-E",
        "outputId": "17184418-1681-4531-9af8-533acca0bf1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['books', 'electronics', 'grocery', 'movies', 'restaurants', 'tripadvisor']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@ LOADING THE DATASET:\n",
        "domains = get_dataset_config_names(\"subjqa\")                # Getting domain names. \n",
        "domains                                                     # Inspection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "11c59e395f42407cbf643551dce8429f",
            "f2359bd552a24e0699d84c1cc5ad1758",
            "f9412b58b953453a98d25ead2d6a8375",
            "86e51fda82194d77ad58bb6cb70fae9b",
            "ab08c9ca19484b2d8b0cd2542ef092e8",
            "78289908fa0347d989262ba6b7cded07",
            "767266f0c8ce4f99ae3a14f8c8b45d82",
            "f8e01741b0694071bd8bb905d6bf27ad",
            "b29ae6f11520447284ad5ed7f4f21a89",
            "38c09996a2ac455383e7904f511110ed",
            "58eb034ea252457b8b39d87ff28861cb"
          ]
        },
        "id": "hgOtwLMcqzIH",
        "outputId": "06111437-2a43-4be5-c0b5-5baef3d89a96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING - datasets.builder -  Reusing dataset subjqa (/root/.cache/huggingface/datasets/subjqa/electronics/1.1.0/e5588f9298ff2d70686a00cc377e4bdccf4e32287459e3c6baf2dc5ab57fe7fd)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11c59e395f42407cbf643551dce8429f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': ['Bass is weak as expected', 'Bass is weak as expected, even with EQ adjusted up'], 'answer_start': [1302, 1302], 'answer_subj_level': [1, 1], 'ans_subj_score': [0.5083333253860474, 0.5083333253860474], 'is_ans_subjective': [True, True]}\n"
          ]
        }
      ],
      "source": [
        "#@ LOADING THE DATASET:\n",
        "subjqa = load_dataset(\"subjqa\", name=\"electronics\")         # Initializing electronics qa. \n",
        "print(subjqa[\"train\"][\"answers\"][1])                        # Inspecting answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G84ULSTmtcip",
        "outputId": "b90bd80a-a6d7-4389-9558-026b52b88baa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of questions in train: 1295\n",
            "Number of questions in test: 358\n",
            "Number of questions in validation: 255\n"
          ]
        }
      ],
      "source": [
        "#@ INSPECTING THE DATASET:\n",
        "dfs = {split: dset.to_pandas() for split,dset in subjqa.flatten().items()}  # Initialization.\n",
        "for split, df in dfs.items():\n",
        "    print(f\"Number of questions in {split}: {df['id'].nunique()}\")          # Inspecton."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "7M8MNUbSu26P",
        "outputId": "75cbc630-90ec-409a-f929-4ae2f8457c20"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bab0c68f-7481-49af-be9e-9fddb489184d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>question</th>\n",
              "      <th>answers.text</th>\n",
              "      <th>answers.answer_start</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>791</th>\n",
              "      <td>B005DKZTMG</td>\n",
              "      <td>Does the keyboard lightweight?</td>\n",
              "      <td>[this keyboard is compact]</td>\n",
              "      <td>[215]</td>\n",
              "      <td>I really like this keyboard.  I give it 4 stars because it doesn't have a CA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1159</th>\n",
              "      <td>B00AAIPT76</td>\n",
              "      <td>How is the battery?</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>I bought this after the first spare gopro battery I bought wouldn't hold a c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bab0c68f-7481-49af-be9e-9fddb489184d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bab0c68f-7481-49af-be9e-9fddb489184d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bab0c68f-7481-49af-be9e-9fddb489184d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           title                        question                answers.text  \\\n",
              "791   B005DKZTMG  Does the keyboard lightweight?  [this keyboard is compact]   \n",
              "1159  B00AAIPT76             How is the battery?                          []   \n",
              "\n",
              "     answers.answer_start  \\\n",
              "791                 [215]   \n",
              "1159                   []   \n",
              "\n",
              "                                                                              context  \n",
              "791   I really like this keyboard.  I give it 4 stars because it doesn't have a CA...  \n",
              "1159  I bought this after the first spare gopro battery I bought wouldn't hold a c...  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@ PREPARING THE DATASET: \n",
        "qa_cols = [\"title\", \"question\", \"answers.text\", \"answers.answer_start\", \n",
        "           \"context\"]                                                       # Initialization.\n",
        "sample_df = dfs[\"train\"][qa_cols].sample(2, random_state=7)                 # Initializing sample dataframe. \n",
        "sample_df                                                                   # Inspecting dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J1zdT0ONyyNN",
        "outputId": "b983b20f-b7e3-4868-9fb4-abe03a1ba10b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'this keyboard is compact'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@ INSPECTING THE ANSWER:\n",
        "start_index = sample_df[\"answers.answer_start\"].iloc[0][0]                  # Initializing starting index.\n",
        "end_index = start_index + len(sample_df[\"answers.text\"].iloc[0][0])         # Initializing ending index.\n",
        "sample_df[\"context\"].iloc[0][start_index:end_index]                         # Inspecting answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "vfz8ZM560H2D",
        "outputId": "730c8a00-6e12-4fd4-ecdf-ba23126fadc9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@ INSPECTING THE QUESTION:\n",
        "counts = {}                                                                       # Initialization.\n",
        "question_types = [\"What\", \"How\", \"Is\", \"Does\", \"Do\", \"Was\", \"Where\",\"Why\"]        # Initializing question words.\n",
        "for q in question_types:\n",
        "    counts[q] = dfs[\"train\"][\"question\"].str.startswith(q).value_counts()[True]   # Initializing value counts.\n",
        "pd.Series(counts).sort_values().plot.barh()                                       # Creating plots.\n",
        "plt.title(\"Frequency of Question Types\")                                          # Initialization.\n",
        "plt.show()                                                                        # Inspection. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HiOh7McNU-W",
        "outputId": "bae67dac-2b03-44b8-83e4-128d511d2af4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How are the bass?\n",
            "How is the camera?\n",
            "How is the speed?\n",
            "What is the quality of the customer service?\n",
            "What do you think about detail?\n",
            "What is amount?\n",
            "Is the option available?\n",
            "Is the hole big or small?\n",
            "Is this how zoom works?\n"
          ]
        }
      ],
      "source": [
        "#@ INSPECTING QUESTIONS WITH START WORDS: \n",
        "for question_type in [\"How\", \"What\", \"Is\"]:\n",
        "    for question in (dfs[\"train\"][dfs[\"train\"].question.str.startswith(question_type)]\n",
        "                     .sample(n=3, random_state=2022)[\"question\"]):\n",
        "        print(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i44nrUB7nfTu"
      },
      "source": [
        "**Extracting Answers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKqGx7fSjBCJ",
        "outputId": "18f3af23-87a7-47c8-8dfa-24bcff4acb02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS] how much music can this hold? [SEP] an mp3 is about 1 mb / minute, so about 6000 hours depending on file size. [SEP]\n"
          ]
        }
      ],
      "source": [
        "#@ TOKENIZING TEXT FOR QUESTION ANSWERING: SAMPLE EXAMPLE:\n",
        "model_ckpt = \"deepset/minilm-uncased-squad2\"                        # Initializing model checkpoint.\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)               # Initializing pretrained tokenizer.\n",
        "question = \"How much music can this hold?\"                          # Initializing question.\n",
        "context = \"An MP3 is about 1 MB/minute, so about 6000 hours \\\n",
        "           depending on file size.\"                                 # Initializing context.\n",
        "inputs = tokenizer(question, context, return_tensors=\"pt\")          # Initializing input tensors.\n",
        "print(tokenizer.decode(inputs[\"input_ids\"][0]))                     # Decoding IDs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1uHf4fFv52w"
      },
      "source": [
        "**Training Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxqCPji4ujBy",
        "outputId": "5f1f2f94-ae2c-452b-ad27-17a9130bc839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-0.9862, -4.7750, -5.4025, -5.2378, -5.2863, -5.5117, -4.9819, -6.1880,\n",
            "         -0.9862,  0.2596, -0.2144, -1.7136,  3.7806,  4.8561, -1.0546, -3.9097,\n",
            "         -1.7374, -4.5944, -1.4278,  3.9949,  5.0391, -0.2018, -3.0193, -4.8549,\n",
            "         -2.3107, -3.5110, -3.5713, -0.9862]]), end_logits=tensor([[-0.9623, -5.4733, -5.0326, -5.1639, -5.4278, -5.5151, -5.1749, -4.6233,\n",
            "         -0.9623, -3.7855, -0.8715, -3.7745, -3.0162, -1.1780,  0.1758, -2.7365,\n",
            "          4.8934,  0.3046, -3.1761, -3.2762,  0.8937,  5.6606, -0.3623, -4.9554,\n",
            "         -3.2531, -0.0914,  1.6211, -0.9623]]), hidden_states=None, attentions=None)\n"
          ]
        }
      ],
      "source": [
        "#@ TRAINING THE QA MODEL:\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)   # Initializing pretrained model.\n",
        "with torch.no_grad():                                               # Clearing gradients.\n",
        "    outputs = model(**inputs)                                       # Implementation of model.\n",
        "print(outputs)                                                      # Inspection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9kPFqo2xxYe",
        "outputId": "59ca71c5-c0ca-4e81-d062-9c1e5bfca768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input IDs shape: torch.Size([1, 28])\n",
            "Start logits shape: torch.Size([1, 28])\n",
            "End logits shape: torch.Size([1, 28])\n"
          ]
        }
      ],
      "source": [
        "#@ INSPECTING MODEL OUTPUT ANSWERS: \n",
        "start_logits = outputs.start_logits                                 # Initializing output start logits.\n",
        "end_logits = outputs.end_logits                                     # Initializing output end logits.\n",
        "print(f\"Input IDs shape: {inputs.input_ids.size()}\")                # Inspection. \n",
        "print(f\"Start logits shape: {start_logits.size()}\")                 # Inspection.\n",
        "print(f\"End logits shape: {end_logits.size()}\")                     # Inspection. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dZ1NA0JJdEf",
        "outputId": "da85b79f-cc27-4201-f483-59899d183adf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: How much music can this hold?\n",
            "Answer: 6000 hours\n"
          ]
        }
      ],
      "source": [
        "#@ DECODING THE OUTPUT LOGITS:\n",
        "start_idx = torch.argmax(start_logits)                              # Index of maximum tensor.\n",
        "end_idx = torch.argmax(end_logits) + 1                              # Index of maximum tensor.\n",
        "answer_span = inputs[\"input_ids\"][0][start_idx:end_idx]             # Initializing answers.\n",
        "answer = tokenizer.decode(answer_span)                              # Decoding answers.\n",
        "print(f\"Question: {question}\")                                      # Inspecting question. \n",
        "print(f\"Answer: {answer}\")                                          # Inspecting answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL-iow12hQoX",
        "outputId": "62b72046-4cfe-4164-acbd-40ae009ff422"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'answer': '6000 hours', 'end': 48, 'score': 0.2651623487472534, 'start': 38},\n",
              " {'answer': '1 MB/minute, so about 6000 hours',\n",
              "  'end': 48,\n",
              "  'score': 0.22082945704460144,\n",
              "  'start': 16},\n",
              " {'answer': '1 MB/minute',\n",
              "  'end': 27,\n",
              "  'score': 0.10253474861383438,\n",
              "  'start': 16}]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@ QUESTION ANSWERING WITH TRANSFORMERS PIPELINE:\n",
        "pipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)     # Initializing model pipeline.\n",
        "pipe(question=question, context=context, topk=3)                            # Inspecting output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvnWD6LWh_Ae",
        "outputId": "1f9a84f3-4280-4cdf-b6cf-f3c78a192ea8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'answer': '', 'end': 0, 'score': 0.9068416357040405, 'start': 0}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@ INSPECTING QA WITH NO ANSWERS:\n",
        "pipe(question=\"Why is there no data?\", context=context, handle_impossible_answer=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgNIR954mMAZ"
      },
      "source": [
        "**Dealing with Long Sequences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCQ4RaM_ioWt",
        "outputId": "1b39f3f7-2680-4d34-cd9a-fdc68c992f2d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Window #0 has 100 tokens.\n",
            "Window #1 has 88 tokens.\n"
          ]
        }
      ],
      "source": [
        "#@ DEALING WITH LONG SEQUENCES:\n",
        "example = dfs[\"train\"].iloc[0][[\"question\", \"context\"]]                        # Initializing sample.\n",
        "tokenized_example = tokenizer(example[\"question\"], example[\"context\"], \n",
        "                              return_overflowing_tokens=True, max_length=100,\n",
        "                              stride=25)                                       # Tokenizing with sliding window.\n",
        "for idx, window in enumerate(tokenized_example[\"input_ids\"]):\n",
        "    print(f\"Window #{idx} has {len(window)} tokens.\")                          # Inspecting number of tokens. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRhzj8L9nnto",
        "outputId": "8e39d2b9-abb8-47d8-8f69-4ee8555f21dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS] how is the bass? [SEP] i have had koss headphones in the past, pro 4aa and qz - 99. the koss portapro is portable and has great bass response. the work great with my android phone and can be \" rolled up \" to be carried in my motorcycle jacket or computer bag without getting crunched. they are very light and don't feel heavy or bear down on your ears even after listening to music with them on all day. the sound is [SEP]\n",
            "\n",
            "[CLS] how is the bass? [SEP] and don't feel heavy or bear down on your ears even after listening to music with them on all day. the sound is night and day better than any ear - bud could be and are almost as good as the pro 4aa. they are \" open air \" headphones so you cannot match the bass to the sealed types, but it comes close. for $ 32, you cannot go wrong. [SEP]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@ DECODING THE OUTPUTS:\n",
        "for window in tokenized_example[\"input_ids\"]:\n",
        "    print(f\"{tokenizer.decode(window)}\\n\")                                     # Decoding the outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywMsrE6TM9KV"
      },
      "source": [
        "**Haystack and QA Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NeCEI9Voy5g"
      },
      "outputs": [],
      "source": [
        "#@ INITIALIZING A DOCUMENT STORE: ELASTICSEARCH:\n",
        "url = \"\"\"https://artifacts.elastic.co/downloads/elasticsearch/\\\n",
        "elasticsearch-7.9.2-linux-x86_64.tar.gz\"\"\"\n",
        "!wget -nc -q {url}\n",
        "!tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtpypDKtNhx7"
      },
      "outputs": [],
      "source": [
        "#@ RUNNING ELASTIC SEARCH:\n",
        "!chown -R daemon:daemon elasticsearch-7.9.2\n",
        "es_server = Popen(args=['elasticsearch-7.9.2/bin/elasticsearch'],\n",
        "                  stdout=PIPE, stderr=STDOUT, preexec_fn=lambda: os.setuid(1))\n",
        "!sleep 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPQaWA6pOaGB",
        "outputId": "d1f6cdee-87bc-4bcf-ec8d-fd1dee989ab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"name\" : \"49ab305baa2f\",\n",
            "  \"cluster_name\" : \"elasticsearch\",\n",
            "  \"cluster_uuid\" : \"pSaHcxQsTRCJs7z6HYyTBQ\",\n",
            "  \"version\" : {\n",
            "    \"number\" : \"7.9.2\",\n",
            "    \"build_flavor\" : \"default\",\n",
            "    \"build_type\" : \"tar\",\n",
            "    \"build_hash\" : \"d34da0ea4a966c4e49417f2da2f244e3e97b4e6e\",\n",
            "    \"build_date\" : \"2020-09-23T00:45:33.626720Z\",\n",
            "    \"build_snapshot\" : false,\n",
            "    \"lucene_version\" : \"8.6.2\",\n",
            "    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n",
            "    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n",
            "  },\n",
            "  \"tagline\" : \"You Know, for Search\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "#@ INSPECTION OF ELASTICSEARCH:\n",
        "!curl -X GET \"localhost:9200/?pretty\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh73IWzq12je"
      },
      "outputs": [],
      "source": [
        "#@ CLEANING DOCUMENT STORE: \n",
        "document_store = ElasticsearchDocumentStore(return_embedding=True)                          # Initializing document store.\n",
        "if len(document_store.get_all_documents()) or len(document_store.get_all_labels()) > 0:\n",
        "    document_store.delete_documents(\"document\")                                             # Cleaning document store. \n",
        "    document_store.delete_documents(\"label\")                                                # Cleaning document store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pOwpl22TKfS",
        "outputId": "6351cbd0-c26c-4737-977a-da00eb249f9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 1615 documents\n"
          ]
        }
      ],
      "source": [
        "#@ INSTANTIATING DOCUMENT STORE:\n",
        "for split, df in dfs.items():\n",
        "    docs = [{\"content\": row[\"context\"],\n",
        "             \"meta\": {\"item_id\": row[\"title\"], \"question_id\": row[\"id\"],\n",
        "                      \"split\": split}} \n",
        "            for _, row in df.drop_duplicates(subset=\"context\").iterrows()]  # Preparing haystack document store.\n",
        "    document_store.write_documents(docs, index=\"document\")\n",
        "print(f\"Loaded {document_store.get_document_count()} documents\")            # Inspecting number of documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYfStTs55M5F"
      },
      "source": [
        "**Initializing Retriever**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzgMkCRB3MlF",
        "outputId": "0a002fd4-6452-44e0-f9a2-c98a7ac7d0ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING - haystack.nodes.retriever.sparse -  This class is now deprecated. Please use the BM25Retriever instead\n",
            "WARNING - haystack.nodes.base -  Unnamed __init__ parameters will not be saved to YAML if Pipeline.save_to_yaml() is called!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Document: id=252e83e25d52df7311d597dc89eef9f6, content='This is a gift to myself.  I have been a kindle user for 4 years and this is my third one.  I never  ...'>\n"
          ]
        }
      ],
      "source": [
        "#@ INITIALIZING RETRIEVER: \n",
        "es_retriever = ElasticsearchRetriever(document_store=document_store)        # Initializing retriever. \n",
        "item_id = \"B0074BW614\"                                                      # Initialization. \n",
        "query = \"Is it good for reading?\"                                           # Initializing question.\n",
        "retrieved_docs = es_retriever.retrieve(query=query, top_k=3,\n",
        "                                       filters={\"item_id\":[item_id], \n",
        "                                                \"split\": [\"train\"]})        # Initializing retrieved docs. \n",
        "print(retrieved_docs[0])                                                    # Inspection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg4BLo41NxHL"
      },
      "source": [
        "**Initializing Reader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbrLwhUI_QmE",
        "outputId": "e8dab0a9-e040-4b5a-e68e-26933fe5ab45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
            "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
            "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
            "INFO - haystack.modeling.model.language_model -  =============\n",
            "INFO - haystack.modeling.model.language_model -  Could not find deepset/minilm-uncased-squad2 locally.\n",
            "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
            "INFO - haystack.modeling.model.language_model -  Loaded deepset/minilm-uncased-squad2\n",
            "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
            "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
            "INFO - haystack.modeling.infer -  Got ya 2 parallel workers to do inference ...\n",
            "INFO - haystack.modeling.infer -   0     0  \n",
            "INFO - haystack.modeling.infer -  /w\\   /w\\ \n",
            "INFO - haystack.modeling.infer -  /'\\   / \\ \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'query': 'How much music can this hold?', 'no_ans_gap': 12.648086071014404, 'answers': [<Answer {'answer': '6000 hours', 'type': 'extractive', 'score': 0.5294052958488464, 'context': 'An MP3 is about 1 MB/minute, so about 6000 hours            depending on file size.', 'offsets_in_document': [{'start': 38, 'end': 48}], 'offsets_in_context': [{'start': 38, 'end': 48}], 'document_id': 'd94ae183d33b425b6d4b3ba4507a4e3', 'meta': {}}>]}\n"
          ]
        }
      ],
      "source": [
        "#@ INITIALIZING READER:\n",
        "model_ckpt = \"deepset/minilm-uncased-squad2\"                                # Initializing model checkpoint. \n",
        "max_seq_length, doc_stride = 348, 128                                       # Initialization.\n",
        "reader = FARMReader(model_name_or_path=model_ckpt, progress_bar=False,\n",
        "                    max_seq_len=max_seq_length, doc_stride=doc_stride,\n",
        "                    return_no_answer=True)                                  # Initializing reader.\n",
        "print(reader.predict_on_texts(question=question, texts=[context], top_k=1)) # Inspection. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV3_DKHXzI9f"
      },
      "source": [
        "**Improving QA Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz1YMeTDyz4j",
        "outputId": "49e0c43a-1b20-496c-8dd9-8db700085d7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING - haystack.nodes.evaluator.evaluator -  EvalDocuments node is deprecated and will be removed in a future version. Please use pipeline.eval() instead.\n"
          ]
        }
      ],
      "source": [
        "#@ EVALUATING RETRIEVER:\n",
        "class EvalRetrieverPipeline:                                                # Defining class.\n",
        "    def __init__(self, retriever):                                          # Initializing constructor function.\n",
        "        self.retriever = retriever                                          # Initializing retriever.\n",
        "        self.eval_retriever = EvalDocuments()                               # Initializing eval retriever.\n",
        "        pipe = Pipeline()                                                   # Initializing pipeline.\n",
        "        pipe.add_node(component=self.retriever, name=\"ESRetriever\", \n",
        "                      inputs=[\"Query\"])                                     # Adding node to pipeline. \n",
        "        pipe.add_node(component=self.eval_retriever, name=\"EvalRetriever\",\n",
        "                      inputs=[\"ESRetriever\"])                               # Adding node to pipeline. \n",
        "        self.pipeline = pipe                                                # Initializing pipeline.\n",
        "\n",
        "#@ IMPLEMENTATION OF RETRIEVER:\n",
        "pipe = EvalRetrieverPipeline(es_retriever)                                  # Initializing eval retriever pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "6kmF_Xpy8tPW",
        "outputId": "8aa97f47-31bd-44ec-b088-db59d8f5402f"
      },
      "outputs": [],
      "source": [
        "#@ INITIALIZING HAYSTACK LABELS:\n",
        "labels = []                                                                 # Initialization.\n",
        "for i,row in dfs[\"test\"].iterrows():\n",
        "    meta = {\"item_id\":row[\"title\"], \"question_id\":row[\"id\"]}                # Initializing metadata.\n",
        "    if len(row[\"answers.text\"]):\n",
        "        for answer in row[\"answers.text\"]:\n",
        "            label = Label(query=row[\"question\"], answer=answer,\n",
        "                          id=i, origin=row[\"id\"], meta=meta, \n",
        "                          is_correct_answer=True, \n",
        "                          is_correct_document=True, no_answer=False)        # Initializing label.\n",
        "            labels.append(label)                                            # Adding labels.\n",
        "    else:\n",
        "        label = Label(query=row[\"question\"], answer=\"\", id=i, \n",
        "                      origin=row[\"id\"], meta=meta, is_correct_answer=True, \n",
        "                      is_correct_document=True, no_answer=True)             # Initializing label\n",
        "        labels.append(label)                                                # Adding to labels.\n",
        "\n",
        "#@ INSPECTING A LABEL:\n",
        "print(labels[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "QuestionAnswering.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "11c59e395f42407cbf643551dce8429f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2359bd552a24e0699d84c1cc5ad1758",
              "IPY_MODEL_f9412b58b953453a98d25ead2d6a8375",
              "IPY_MODEL_86e51fda82194d77ad58bb6cb70fae9b"
            ],
            "layout": "IPY_MODEL_ab08c9ca19484b2d8b0cd2542ef092e8"
          }
        },
        "38c09996a2ac455383e7904f511110ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58eb034ea252457b8b39d87ff28861cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "767266f0c8ce4f99ae3a14f8c8b45d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78289908fa0347d989262ba6b7cded07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86e51fda82194d77ad58bb6cb70fae9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38c09996a2ac455383e7904f511110ed",
            "placeholder": "​",
            "style": "IPY_MODEL_58eb034ea252457b8b39d87ff28861cb",
            "value": " 3/3 [00:00&lt;00:00, 44.84it/s]"
          }
        },
        "ab08c9ca19484b2d8b0cd2542ef092e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b29ae6f11520447284ad5ed7f4f21a89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2359bd552a24e0699d84c1cc5ad1758": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78289908fa0347d989262ba6b7cded07",
            "placeholder": "​",
            "style": "IPY_MODEL_767266f0c8ce4f99ae3a14f8c8b45d82",
            "value": "100%"
          }
        },
        "f8e01741b0694071bd8bb905d6bf27ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9412b58b953453a98d25ead2d6a8375": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8e01741b0694071bd8bb905d6bf27ad",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b29ae6f11520447284ad5ed7f4f21a89",
            "value": 3
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
