## **Named Entity Recognition**

The [**NER**](https://github.com/ThinamXx/Transformers_NLP/blob/main/02.%20NLP%20with%20Transformers/04.%20Named%20Entity%20Recognition/NER.ipynb) notebook contains information and implementation of Named Entity Recognition, PAN-X Dataset, Multilingual Transformers, Tokenization, SentencePiece Tokenizer, Performance Measures, Fine-Tuning XLM-Roberta, Error Analysis, Cross-Lingual Transfer and Fine-Tuning with Multiple Languages. 

**Note:**
  - üìù[**NER**](https://github.com/ThinamXx/Transformers_NLP/blob/main/02.%20NLP%20with%20Transformers/04.%20Named%20Entity%20Recognition/NER.ipynb)

**Named Entity Recognition**
- NER is a common NLP task that identifies entities like people, organizations or locations in text. These entities can be used for various applications such as gaining insights from documents, augmenting the quality of search engines, or building a structured database from a corpus.

**Multilingual Transformers**
- Multilingual transformers involve similar architectures and training procedures as their multilingual counterparts, except that the corpus used for pretraining consists of documents in many languages.

**The SentencePiece Tokenizer**
- XLM-R uses a tokenizer called SentencePiece that is trained on the raw text of all one hundred languages. The SentencePiece tokenizer is based on a type of subword segmentation called Unigram and encodes each input text as a sequence of Unicode characters.
