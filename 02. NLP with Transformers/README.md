# **NATURAL LANGUAGE PROCESSING WITH TRANSFORMERS**

The repository contains a list of the projects and notebooks which we have worked on while reading the book **Natural Language Processing with Transformers**.

## **ðŸ“šNOTEBOOKS:**

[**1. HELLO TRANSFORMERS**](https://github.com/ThinamXx/Transformers_NLP/tree/main/02.%20NLP%20with%20Transformers/01.%20Hello%20Transformers)
- The **Hello Transformers** notebook contains information and implementation of Text Classification, Named Entity Recognition, Question Answering, Summarization, Translation and Text Generation using ðŸ¤— Transformers.

[**2. TEXT CLASSIFICATION**](https://github.com/ThinamXx/Transformers_NLP/tree/main/02.%20NLP%20with%20Transformers/02.%20Text%20Classification)
- The **Text Classification** notebook contains information and implementation of Character Tokenization, Word Tokenization, Subword Tokenization, Feature Extraction, Training Logistic Regression & Hidden States, One Hot Encoding, Fine-Tuning Transformers, Confusion Matrix, Performance Metrics and Error Analysis.

[**3. TRANSFORMER ANATOMY**](https://github.com/ThinamXx/Transformers_NLP/tree/main/02.%20NLP%20with%20Transformers/03.%20Transformer%20Anatomy)
- The **Transformer Anatomy** notebook contains information and implementation of The Encoder Transformer Architecture, Scaled Dot Product Attention, Tokenization, Embedding Layer, Softmax Activation Function, Multi-head Attention, Feed-Forward Layer, Layer Normalization and The Decoder Transformer.

[**4. NAMED ENTITY RECOGNITION**](https://github.com/ThinamXx/Transformers_NLP/tree/main/02.%20NLP%20with%20Transformers/04.%20Named%20Entity%20Recognition)
- The **NER** notebook contains information and implementation of Named Entity Recognition, PAN-X Dataset, Multilingual Transformers, Tokenization, SentencePiece Tokenizer, Performance Measures, Fine-Tuning XLM-Roberta, Error Analysis, Cross-Lingual Transfer and Fine-Tuning with Multiple Languages.

[**5. TEXT GENERATION**](https://github.com/ThinamXx/Transformers_NLP/tree/main/02.%20NLP%20with%20Transformers/05.%20Text%20Generation)
- The **Text Generation** notebook contains information and implementation of Greedy Search Decoding, Beam Search Decoding, Sampling Methods, Top-k and Nucleus Sampling.

[**6. TEXT SUMMARIZATION**](https://github.com/ThinamXx/Transformers_NLP/tree/main/02.%20NLP%20with%20Transformers/06.%20Summarization)
- The **Summarization** notebook contains information and implementation of The CNN and DailyMail Dataset, Text Summarization Pipelines, Summarization with PEGASUS, Comparing Summaries, Quality Measurement, BLEU and ROUGE Metrics and Training Summarization Model.

[**7. QUESTION ANSWERING**](https://github.com/ThinamXx/Transformers_NLP/tree/main/02.%20NLP%20with%20Transformers/07.%20Question%20Answering)
- The **Question Answering** notebook contains information and implementation about SubjQA Dataset, Transformers Pipeline, Dealing Long Sequences, Haystack, Document Store, Retriever and Reader.

[**8. TRANSFORMERS IN PRODUCTION**](https://github.com/ThinamXx/Transformers_NLP/tree/main/02.%20NLP%20with%20Transformers/08.%20Transformers%20in%20Production)
- The **Transformers & Production** notebook contains information and implementation of Case Study: Intent Detection, Performance Benchmark, Computing Accuracy, Model Size, Knowledge Distillation, KL Divergence, Hyperparameters with Optuna, Model Quantization, Optimization with ONNX and ONNX Runtime.
