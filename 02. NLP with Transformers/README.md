# **NATURAL LANGUAGE PROCESSING WITH TRANSFORMERS**

The repository contains a list of the projects and notebooks which we have worked on while reading the book **Natural Language Processing with Transformers**.

## **ðŸ“šNOTEBOOKS:**

[**1. HELLO TRANSFORMERS**](https://github.com/ThinamXx/Transformers_NLP/tree/main/02.%20NLP%20with%20Transformers/01.%20Hello%20Transformers)
- The **Hello Transformers** notebook contains information and implementation of Text Classification, Named Entity Recognition, Question Answering, Summarization, Translation and Text Generation using ðŸ¤— Transformers.

[**2. TEXT CLASSIFICATION**](https://github.com/ThinamXx/Transformers_NLP/tree/main/02.%20NLP%20with%20Transformers/02.%20Text%20Classification)
- The **Text Classification** notebook contains information and implementation of Character Tokenization, Word Tokenization, Subword Tokenization, Feature Extraction, Training Logistic Regression & Hidden States, One Hot Encoding, Fine-Tuning Transformers, Confusion Matrix, Performance Metrics and Error Analysis.

[**3. TRANSFORMER ANATOMY**](https://github.com/ThinamXx/Transformers_NLP/tree/main/02.%20NLP%20with%20Transformers/03.%20Transformer%20Anatomy)
- The **Transformer Anatomy** notebook contains information and implementation of The Encoder Transformer Architecture, Scaled Dot Product Attention, Tokenization, Embedding Layer, Softmax Activation Function, Multi-head Attention, Feed-Forward Layer, Layer Normalization and The Decoder Transformer.
